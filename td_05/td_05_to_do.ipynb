{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "597Hu82gSNCZ"
   },
   "source": [
    "<img src=\"https://upload.wikimedia.org/wikipedia/fr/0/0b/Polytech_Lyon_logo.png\" alt=\"drawing\" height=\"200\"/>\n",
    "\n",
    "# Traitement de donnÃ©es & Programmation en Python\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EA-XK862WiMt"
   },
   "source": [
    "# TD 05\n",
    "\n",
    "Traitement de donnÃ©es\n",
    "\n",
    "![Good luck!](https://media.tenor.com/YoFWnXe4V3kAAAAd/may-the-odds-be-ever-in-your-favor-may-the-odds-hunger-games.gif)\n",
    " \n",
    "Elements Ã  consulter:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Doc                                   |             Link\n",
    "--------------------------------------|------------------------------------\n",
    "Github Helper      | [>link<](#scrollTo=Github_101)\n",
    "Python en 30 jours | [>link<](https://moncoachdata.com/courses/apprendre-python-en-30-jours/)\n",
    "Get started with pandas | [>link<](https://colab.research.google.com/notebooks/snippets/pandas.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y1g4EgT41MqJ"
   },
   "source": [
    "## Intro\n",
    "\n",
    "Le premier bloc devrait toujours contenir les installs/imports dont on aura besoin pour le reste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yjiE8c51VoT0",
    "outputId": "2f4856bd-590b-4197-a9f0-e3a020d191eb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python is awesome ðŸ‘\n"
     ]
    }
   ],
   "source": [
    "# Installs\n",
    "print(\"Python is awesome ðŸ‘\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "JhT-50uwz72F"
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import json\n",
    "from random import randint\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NsB9ADLg8i8P",
    "outputId": "162e09d0-12e6-4112-972d-91cea118215a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([[1, 2, 3], [4, 5, 6]], np.int32)\n",
    "\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iKow2OZ5LCXr"
   },
   "source": [
    "### Correction TD precedent\n",
    "\n",
    "Partir d'un fichier csv et alimenter la binge watch list :\n",
    "  > serie, plateform, nb_episodes, annÃ©e_sortie, note\n",
    "\n",
    "Puis print :\n",
    "\n",
    "\t Nom de la sÃ©rie : Brooklyn Nine-Nine\n",
    "\t AnnÃ©e de sortie : 2013\n",
    "\n",
    "\t Nom de la sÃ©rie : The office\n",
    "\t AnnÃ©e de sortie : 2005\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9lcQQFp3w0HE"
   },
   "outputs": [],
   "source": [
    "def csv_to_dict(file_path, separator=\";\", row_limit=None):\n",
    "    \"\"\"\n",
    "    Transforms a csv file, into a list of dictionaries\n",
    "\n",
    "    Arguments:\n",
    "        file_path  {str} : eg. /documents/file.txt\n",
    "        separator  {str} : separator of fields, default (;)\n",
    "        row_limit  {int} : limit the rows to be read, default None\n",
    "\n",
    "    Returns list[dict]\n",
    "    \"\"\"\n",
    "\n",
    "    with open(file_path, \"r\") as f:\n",
    "        serie = {}\n",
    "        serie_list = []\n",
    "        for i, row in enumerate(f, 1):\n",
    "            if i == 1:\n",
    "                header = row.lower().strip().replace(' ','_').split(separator)\n",
    "                # print(\"\\nHeaders:\", header,\"\\n\")\n",
    "            else:\n",
    "                data = row.lower().strip().split(separator)\n",
    "                # print(\"Data:\",data)\n",
    "                if len(header) == len(data):\n",
    "                    for j, element in enumerate(header):\n",
    "                        serie[header[j]] = data[j]\n",
    "            # print(serie)\n",
    "                serie_list.append(serie)\n",
    "                serie = {}\n",
    "            if i == row_limit:\n",
    "                break\n",
    "    return serie_list\n",
    "\n",
    "\n",
    "\n",
    "file_path = \"./netflix_titles.csv\"\n",
    "# file_path = \"./tv_shows_pipe.csv\"\n",
    "limit = None\n",
    "binge_watch_list = csv_to_dict(file_path,separator=\"|\",row_limit=limit)\n",
    "# for serie in binge_watch_list:\n",
    "#   print(serie.get('title'))\n",
    "# # Option 1 read some rows to see what we have\n",
    "\n",
    "df = pd.DataFrame(binge_watch_list)\n",
    "df[\"title\"] = df[\"title\"].str.title()\n",
    "df.head(5)\n",
    "\n",
    "column_name = 'release_year'\n",
    "filter = df['release_year'] == '2005'\n",
    "# df.query(f\"`{column_name}` == '2003'\")\n",
    "df[filter]\n",
    "# # serie, plateform, nb_episodes, annÃ©e_sortie, note\n",
    "# df2 = df.melt(id_vars=['title','year','imdb','rotten_tomatoes'],\n",
    "#               var_name='plateform', \n",
    "#               value_vars=['netflix','hulu','prime_video','disney+'])\n",
    "# df2.drop(['value'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k2lJWv62kQZA"
   },
   "source": [
    "##EX01\n",
    "### Numpy intro\n",
    "\n",
    "* CrÃ©er un vecteur depuis la liste ['Lyon', 'Paris', 'Montpellier']\n",
    "    * Assigner le rÃ©sultat Ã  la variable `villes`\n",
    "* CrÃ©er une matrice depuis la liste de listes suivante: `[['Lyon', '69'], ['Paris', '75'], ['Montpellier','34']]`\n",
    "    * Assigner le rÃ©sultat Ã  la variable `villes_departement`\n",
    "* Assigner la taille du vecteur `villes` Ã  la variable `v_shape`\n",
    "* Assigner la taille du tableau `villes_departement` Ã  la variable `vd_shape` \n",
    "* Afficher les rÃ©sultats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "n_jOsgGllUhC"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Lyon' 'Paris' 'Montpellier']\n",
      "[['Lyon' '69']\n",
      " ['Paris' '75']\n",
      " ['Montpellier' '34']]\n",
      "(3,)\n",
      "(3, 2)\n"
     ]
    }
   ],
   "source": [
    "# Code here\n",
    "villes = np.array(['Lyon','Paris','Montpellier'])\n",
    "villes_departement = np.array([['Lyon','69'],['Paris','75'],['Montpellier','34']])\n",
    "v_shape = villes.shape\n",
    "vd_shape = villes_departement.shape\n",
    "print(villes)\n",
    "print(villes_departement)\n",
    "print(v_shape)\n",
    "print(vd_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q8WBS9oVKcWs"
   },
   "source": [
    "##EX02\n",
    "### Numpy intro\n",
    "\n",
    "#### Part 1\n",
    "\n",
    "* Telecharger le dataset [cereal.csv](https://www.kaggle.com/datasets/crawford/80-cereals?select=cereal.csv) avec les colonnes suivantes :\n",
    "\n",
    "```\n",
    "['name', 'mfr', 'type', 'calories', 'protein', 'fat', 'sodium', 'fiber',\n",
    "'carbo', 'sugars', 'potass', 'vitamins', 'shelf', 'weight', 'cups',\n",
    "'rating']\n",
    "```\n",
    "\n",
    "* Afficher les deux premieres colonnes et toute les lignes\n",
    "* Afficher la derniÃ¨re colonne\n",
    "* Afficher les 5 premieres lignes de la 4Ã¨me colonne\n",
    "* Assigner a une variable `corn_flakes_cals` le nombre de calories par 100 gr de cÃ©rÃ©ales de la marque Corn Flakes \n",
    "* Assigner le nom de la 3eme marque sur le dataset a une variabe `third_brand`\n",
    "* Mettre dans une liste toutes les marques de cÃ©reales en utilisant `.tolist()` & afficher cette derniÃ¨re\n",
    "* Mettre les 10 premiere marques dans le fichiers dans une liste `first_ten_brands` & afficher cette derniÃ¨re\n",
    "> bonus \n",
    "* Convertir la colonne ratings en dÃ©cimale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XTDsqYIgpitx",
    "outputId": "d2cd6d75-cf4d-4421-c34f-097def1f3b94"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(77, 16)\n"
     ]
    }
   ],
   "source": [
    "# Code here\n",
    "file_path = \"./cereal.csv\"\n",
    "data = np.genfromtxt(file_path,\n",
    "                     delimiter=\",\",\n",
    "                     dtype=None,\n",
    "                     encoding=None,\n",
    "                     autostrip=True,\n",
    "                     )\n",
    "data = data[1:,:]\n",
    "print(data.shape) ## retourne (lignes, colonnes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['100% Bran' 'N']\n",
      " ['100% Natural Bran' 'Q']\n",
      " ['All-Bran' 'K']\n",
      " ['All-Bran with Extra Fiber' 'K']\n",
      " ['Almond Delight' 'R']\n",
      " ['Apple Cinnamon Cheerios' 'G']\n",
      " ['Apple Jacks' 'K']\n",
      " ['Basic 4' 'G']\n",
      " ['Bran Chex' 'R']\n",
      " ['Bran Flakes' 'P']\n",
      " [\"Cap'n'Crunch\" 'Q']\n",
      " ['Cheerios' 'G']\n",
      " ['Cinnamon Toast Crunch' 'G']\n",
      " ['Clusters' 'G']\n",
      " ['Cocoa Puffs' 'G']\n",
      " ['Corn Chex' 'R']\n",
      " ['Corn Flakes' 'K']\n",
      " ['Corn Pops' 'K']\n",
      " ['Count Chocula' 'G']\n",
      " [\"Cracklin' Oat Bran\" 'K']\n",
      " ['Cream of Wheat (Quick)' 'N']\n",
      " ['Crispix' 'K']\n",
      " ['Crispy Wheat & Raisins' 'G']\n",
      " ['Double Chex' 'R']\n",
      " ['Froot Loops' 'K']\n",
      " ['Frosted Flakes' 'K']\n",
      " ['Frosted Mini-Wheats' 'K']\n",
      " ['Fruit & Fibre Dates; Walnuts; and Oats' 'P']\n",
      " ['Fruitful Bran' 'K']\n",
      " ['Fruity Pebbles' 'P']\n",
      " ['Golden Crisp' 'P']\n",
      " ['Golden Grahams' 'G']\n",
      " ['Grape Nuts Flakes' 'P']\n",
      " ['Grape-Nuts' 'P']\n",
      " ['Great Grains Pecan' 'P']\n",
      " ['Honey Graham Ohs' 'Q']\n",
      " ['Honey Nut Cheerios' 'G']\n",
      " ['Honey-comb' 'P']\n",
      " ['Just Right Crunchy  Nuggets' 'K']\n",
      " ['Just Right Fruit & Nut' 'K']\n",
      " ['Kix' 'G']\n",
      " ['Life' 'Q']\n",
      " ['Lucky Charms' 'G']\n",
      " ['Maypo' 'A']\n",
      " ['Muesli Raisins; Dates; & Almonds' 'R']\n",
      " ['Muesli Raisins; Peaches; & Pecans' 'R']\n",
      " ['Mueslix Crispy Blend' 'K']\n",
      " ['Multi-Grain Cheerios' 'G']\n",
      " ['Nut&Honey Crunch' 'K']\n",
      " ['Nutri-Grain Almond-Raisin' 'K']\n",
      " ['Nutri-grain Wheat' 'K']\n",
      " ['Oatmeal Raisin Crisp' 'G']\n",
      " ['Post Nat. Raisin Bran' 'P']\n",
      " ['Product 19' 'K']\n",
      " ['Puffed Rice' 'Q']\n",
      " ['Puffed Wheat' 'Q']\n",
      " ['Quaker Oat Squares' 'Q']\n",
      " ['Quaker Oatmeal' 'Q']\n",
      " ['Raisin Bran' 'K']\n",
      " ['Raisin Nut Bran' 'G']\n",
      " ['Raisin Squares' 'K']\n",
      " ['Rice Chex' 'R']\n",
      " ['Rice Krispies' 'K']\n",
      " ['Shredded Wheat' 'N']\n",
      " [\"Shredded Wheat 'n'Bran\" 'N']\n",
      " ['Shredded Wheat spoon size' 'N']\n",
      " ['Smacks' 'K']\n",
      " ['Special K' 'K']\n",
      " ['Strawberry Fruit Wheats' 'N']\n",
      " ['Total Corn Flakes' 'G']\n",
      " ['Total Raisin Bran' 'G']\n",
      " ['Total Whole Grain' 'G']\n",
      " ['Triples' 'G']\n",
      " ['Trix' 'G']\n",
      " ['Wheat Chex' 'R']\n",
      " ['Wheaties' 'G']\n",
      " ['Wheaties Honey Gold' 'G']]\n"
     ]
    }
   ],
   "source": [
    "#Afficher les deux premieres colonnes et toute les lignes\n",
    "print(data[:,:2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['68.402973' '33.983679' '59.425505' '93.704912' '34.384843' '29.509541'\n",
      " '33.174094' '37.038562' '49.120253' '53.313813' '18.042851' '50.764999'\n",
      " '19.823573' '40.400208' '22.736446' '41.445019' '45.863324' '35.782791'\n",
      " '22.396513' '40.448772' '64.533816' '46.895644' '36.176196' '44.330856'\n",
      " '32.207582' '31.435973' '58.345141' '40.917047' '41.015492' '28.025765'\n",
      " '35.252444' '23.804043' '52.076897' '53.371007' '45.811716' '21.871292'\n",
      " '31.072217' '28.742414' '36.523683' '36.471512' '39.241114' '45.328074'\n",
      " '26.734515' '54.850917' '37.136863' '34.139765' '30.313351' '40.105965'\n",
      " '29.924285' '40.692320' '59.642837' '30.450843' '37.840594' '41.503540'\n",
      " '60.756112' '63.005645' '49.511874' '50.828392' '39.259197' '39.703400'\n",
      " '55.333142' '41.998933' '40.560159' '68.235885' '74.472949' '72.801787'\n",
      " '31.230054' '53.131324' '59.363993' '38.839746' '28.592785' '46.658844'\n",
      " '39.106174' '27.753301' '49.787445' '51.592193' '36.187559']\n"
     ]
    }
   ],
   "source": [
    "#Afficher la derniÃ¨re colonne\n",
    "print(data[:,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['70' '120' '70' '50' '110']\n"
     ]
    }
   ],
   "source": [
    "#Afficher les 5 premieres lignes de la 4Ã¨me colonne\n",
    "print(data[:5,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Corn Flakes' 'K' 'C' '100' '2' '0' '290' '1' '21' '2' '35' '25' '1'\n",
      "  '1' '1' '45.863324']]\n",
      "352.7336860670194\n"
     ]
    }
   ],
   "source": [
    "#Assigner a une variable corn_flakes_cals le nombre de calories par 100 gr de cÃ©rÃ©ales de la marque Corn Flakes\n",
    "#1 ounce = 28.35 grams\n",
    "CONVERSION_EN_GRAMS = 28.35\n",
    "filter = data[:,0]=='Corn Flakes'\n",
    "corn_flakes = data[filter]\n",
    "print(corn_flakes)\n",
    "cals = float(corn_flakes[0,3])\n",
    "weight = float(corn_flakes[0,13])*CONVERSION_EN_GRAMS\n",
    "corn_flakes_cals = cals*100/weight\n",
    "print(corn_flakes_cals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All-Bran\n"
     ]
    }
   ],
   "source": [
    "#Assigner le nom de la 3eme marque sur le dataset a une variabe third_brand\n",
    "third_band = data[2,0]\n",
    "print(third_band)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['100% Bran', '100% Natural Bran', 'All-Bran', 'All-Bran with Extra Fiber', 'Almond Delight', 'Apple Cinnamon Cheerios', 'Apple Jacks', 'Basic 4', 'Bran Chex', 'Bran Flakes', \"Cap'n'Crunch\", 'Cheerios', 'Cinnamon Toast Crunch', 'Clusters', 'Cocoa Puffs', 'Corn Chex', 'Corn Flakes', 'Corn Pops', 'Count Chocula', \"Cracklin' Oat Bran\", 'Cream of Wheat (Quick)', 'Crispix', 'Crispy Wheat & Raisins', 'Double Chex', 'Froot Loops', 'Frosted Flakes', 'Frosted Mini-Wheats', 'Fruit & Fibre Dates; Walnuts; and Oats', 'Fruitful Bran', 'Fruity Pebbles', 'Golden Crisp', 'Golden Grahams', 'Grape Nuts Flakes', 'Grape-Nuts', 'Great Grains Pecan', 'Honey Graham Ohs', 'Honey Nut Cheerios', 'Honey-comb', 'Just Right Crunchy  Nuggets', 'Just Right Fruit & Nut', 'Kix', 'Life', 'Lucky Charms', 'Maypo', 'Muesli Raisins; Dates; & Almonds', 'Muesli Raisins; Peaches; & Pecans', 'Mueslix Crispy Blend', 'Multi-Grain Cheerios', 'Nut&Honey Crunch', 'Nutri-Grain Almond-Raisin', 'Nutri-grain Wheat', 'Oatmeal Raisin Crisp', 'Post Nat. Raisin Bran', 'Product 19', 'Puffed Rice', 'Puffed Wheat', 'Quaker Oat Squares', 'Quaker Oatmeal', 'Raisin Bran', 'Raisin Nut Bran', 'Raisin Squares', 'Rice Chex', 'Rice Krispies', 'Shredded Wheat', \"Shredded Wheat 'n'Bran\", 'Shredded Wheat spoon size', 'Smacks', 'Special K', 'Strawberry Fruit Wheats', 'Total Corn Flakes', 'Total Raisin Bran', 'Total Whole Grain', 'Triples', 'Trix', 'Wheat Chex', 'Wheaties', 'Wheaties Honey Gold']\n"
     ]
    }
   ],
   "source": [
    "#Mettre dans une liste toutes les marques de cÃ©reales en utilisant .tolist() & afficher cette derniÃ¨re\n",
    "brands = data[:,0].tolist()\n",
    "print(brands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['100% Bran', '100% Natural Bran', 'All-Bran', 'All-Bran with Extra Fiber', 'Almond Delight', 'Apple Cinnamon Cheerios', 'Apple Jacks', 'Basic 4', 'Bran Chex', 'Bran Flakes']\n"
     ]
    }
   ],
   "source": [
    "#Mettre les 10 premiere marques dans le fichiers dans une liste first_ten_brands & afficher cette derniÃ¨re\n",
    "first_ten_brands = brands[:10]\n",
    "print(first_ten_brands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([68.402973, 33.983679, 59.425505, 93.704912, 34.384843, 29.509541,\n",
       "       33.174094, 37.038562, 49.120253, 53.313813, 18.042851, 50.764999,\n",
       "       19.823573, 40.400208, 22.736446, 41.445019, 45.863324, 35.782791,\n",
       "       22.396513, 40.448772, 64.533816, 46.895644, 36.176196, 44.330856,\n",
       "       32.207582, 31.435973, 58.345141, 40.917047, 41.015492, 28.025765,\n",
       "       35.252444, 23.804043, 52.076897, 53.371007, 45.811716, 21.871292,\n",
       "       31.072217, 28.742414, 36.523683, 36.471512, 39.241114, 45.328074,\n",
       "       26.734515, 54.850917, 37.136863, 34.139765, 30.313351, 40.105965,\n",
       "       29.924285, 40.69232 , 59.642837, 30.450843, 37.840594, 41.50354 ,\n",
       "       60.756112, 63.005645, 49.511874, 50.828392, 39.259197, 39.7034  ,\n",
       "       55.333142, 41.998933, 40.560159, 68.235885, 74.472949, 72.801787,\n",
       "       31.230054, 53.131324, 59.363993, 38.839746, 28.592785, 46.658844,\n",
       "       39.106174, 27.753301, 49.787445, 51.592193, 36.187559])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Convertir la colonne ratings en dÃ©cimale\n",
    "data[:,-1].astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8BaW1VvWXCS7"
   },
   "source": [
    "#### Part 2\n",
    "\n",
    "* **Extraire** la premiere colonne du dataset et **la comparer** Ã  la valeur `'Special K'` Assigner le resultat Ã  une variable `special_k`\n",
    "* Executer la commande `print(data[special_k])`\n",
    "> bonus\n",
    "* Faire la meme chose mais le filtre verifie que le manufacturer est Quaker Oats (lire la doc du dataset ðŸ˜‰)\n",
    "> bonus Â²\n",
    "* Print le nom des marques dont le fabricant est `Quaker Oats` et qui contiennent **moins** de `10 grammes` de sucre par portion\n",
    "* Ajouter une marque de cÃ©rÃ©ales \"healthy\" avec 0 grammes de sucre au dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GuXFyhUepnMc",
    "outputId": "6ec9c05d-a76c-4d8f-8c48-6285d32b6953"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Special K' 'K' 'C' '110' '6' '0' '230' '1' '16' '3' '55' '25' '1' '1'\n",
      "  '1' '53.131324']]\n",
      "['100% Natural Bran' 'Life' 'Puffed Rice' 'Puffed Wheat'\n",
      " 'Quaker Oat Squares' 'Quaker Oatmeal']\n"
     ]
    }
   ],
   "source": [
    "# Code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Special K' 'K' 'C' '110' '6' '0' '230' '1' '16' '3' '55' '25' '1' '1'\n",
      "  '1' '53.131324']]\n",
      "[['100% Natural Bran' 'Q' 'C' '120' '3' '5' '15' '2' '8' '8' '135' '0'\n",
      "  '3' '1' '1' '33.983679']\n",
      " [\"Cap'n'Crunch\" 'Q' 'C' '120' '1' '2' '220' '0' '12' '12' '35' '25' '2'\n",
      "  '1' '0.75' '18.042851']\n",
      " ['Honey Graham Ohs' 'Q' 'C' '120' '1' '2' '220' '1' '12' '11' '45' '25'\n",
      "  '2' '1' '1' '21.871292']\n",
      " ['Life' 'Q' 'C' '100' '4' '2' '150' '2' '12' '6' '95' '25' '2' '1'\n",
      "  '0.67' '45.328074']\n",
      " ['Puffed Rice' 'Q' 'C' '50' '1' '0' '0' '0' '13' '0' '15' '0' '3' '0.5'\n",
      "  '1' '60.756112']\n",
      " ['Puffed Wheat' 'Q' 'C' '50' '2' '0' '0' '1' '10' '0' '50' '0' '3' '0.5'\n",
      "  '1' '63.005645']\n",
      " ['Quaker Oat Squares' 'Q' 'C' '100' '4' '1' '135' '2' '14' '6' '110'\n",
      "  '25' '3' '1' '0.5' '49.511874']\n",
      " ['Quaker Oatmeal' 'Q' 'H' '100' '5' '2' '0' '2.7' '-1' '-1' '110' '0'\n",
      "  '1' '1' '0.67' '50.828392']]\n",
      "['100% Natural Bran' 'Life' 'Puffed Rice' 'Puffed Wheat'\n",
      " 'Quaker Oat Squares' 'Quaker Oatmeal']\n"
     ]
    }
   ],
   "source": [
    "special_k = data[:,0] == 'Special K'\n",
    "print(data[special_k])         \n",
    "quaker_oats = data[:,1] == 'Q'\n",
    "print(data[quaker_oats])\n",
    "#* Print le nom des marques dont le fabricant est `Quaker Oats` et qui contiennent **moins** de `10 grammes` de sucre par portion\n",
    "filter = np.logical_and(quaker_oats,data[:,9].astype(int) <10)\n",
    "print(data[filter][:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "[['healthy' '0.0' '0.0' '0.0' '0.0' '0.0' '0.0' '0.0' '0.0' '0' '0.0'\n",
      "  '0.0' '0.0' '0.0' '0.0' '0.0']]\n",
      "['healthy' '0.0' '0.0' '0.0' '0.0' '0.0' '0.0' '0.0' '0.0' '0' '0.0' '0.0'\n",
      " '0.0' '0.0' '0.0' '0.0']\n"
     ]
    }
   ],
   "source": [
    "#* Ajouter une marque de cÃ©rÃ©ales \"healthy\" avec 0 grammes de sucre au dataset \n",
    "new_brand = np.zeros([1,16])\n",
    "print(new_brand)\n",
    "new_brand = new_brand.astype(str)\n",
    "new_brand[0,0] = \"healthy\"\n",
    "new_brand[0,9] = \"0\"\n",
    "print(new_brand)\n",
    "data = np.append(data,new_brand,axis=0)\n",
    "print(data[-1,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NdsY64gl_0dw"
   },
   "source": [
    "#### Part 3\n",
    "\n",
    "Sur le mÃªme dataset, Ã  l'aide d'une boucle `for`:\n",
    "\n",
    "\n",
    "*   CrÃ©er un dictionnaire avec la moyenne de sucre par Fabricant de cÃ©rales\n",
    "*   Trouver la marque de cÃ©reales qui contient le plus de sucre par portion\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EjbTgYNbCaIj",
    "outputId": "5ab1f623-f8df-45f2-e82b-7031da73f3f5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['100% Bran', 'Nabisco', 'C', ..., '1', '0.33', '68.402973'],\n",
       "       ['100% Natural Bran', 'Quaker Oats', 'C', ..., '1', '1',\n",
       "        '33.983679'],\n",
       "       ['All-Bran', 'Kelloggs', 'C', ..., '1', '0.33', '59.425505'],\n",
       "       ...,\n",
       "       ['Wheat Chex', 'Ralston Purina', 'C', ..., '1', '0.67',\n",
       "        '49.787445'],\n",
       "       ['Wheaties', 'General Mills', 'C', ..., '1', '1', '51.592193'],\n",
       "       ['Wheaties Honey Gold', 'General Mills', 'C', ..., '1', '0.75',\n",
       "        '36.187559']], dtype='<U75')"
      ]
     },
     "execution_count": 469,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w1wjqra3_yZo",
    "outputId": "ea12a660-30c6-45d0-e066-c7f4848eb455"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Ralston Purina': 6.125, 'Nabisco': 1.8333333333333333, 'General Mills': 7.954545454545454, 'Kelloggs': 7.565217391304348, 'American Home Food Products': 3.0, 'Post': 8.777777777777779, 'Quaker Oats': 5.25}\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'American Home Food Products': 3.0, 'General Mills': 7.954545454545454, 'Kelloggs': 7.565217391304348, 'Nabisco': 1.8333333333333333, 'Post': 8.777777777777779, 'Quaker Oats': 5.25, 'Ralston Purina': 6.125}\n"
     ]
    }
   ],
   "source": [
    "#CrÃ©er un dictionnaire avec la moyenne de sucre par Fabricant de cÃ©rales\n",
    "fabricants = [ ('A','American Home Food Products'),('G','General Mills'),('K','Kelloggs'),('N','Nabisco'),('P','Post')\n",
    "              ,('Q','Quaker Oats'),('R','Ralston Purina')]\n",
    "dict_moyenne_sucre = {}\n",
    "for fab in fabricants :\n",
    "    #filtrer uniquement manufracturer (mfr) = initial dans la liste fabricants\n",
    "    filter = data[:,1] == fab[0]\n",
    "    #rÃ©cupÃ©rer la colonne sugars du dataset et la transformer en intÃ©ger\n",
    "    sucres = data[filter][:,9].astype(int)\n",
    "    moyenne_sucre = sucres.mean()\n",
    "    dict_moyenne_sucre[fab[1]] = moyenne_sucre\n",
    "\n",
    "print(dict_moyenne_sucre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Golden Crisp' 'Smacks']\n"
     ]
    }
   ],
   "source": [
    "#Trouver la marque de cÃ©reales qui contient le plus de sucre par portion\n",
    "#Extraire la colonne sugars du dataset et la tranformer en intÃ©ger\n",
    "sucres = data[:,9].astype(int)\n",
    "#trouver la maximumm nombre de sucres\n",
    "max_sucres = sucres.max()\n",
    "#filtrer les marques qui ont la quantitÃ© de sucres Ã©gale Ã  max_sucres\n",
    "filter = data[:,9].astype(int) == max_sucres\n",
    "array_max_sucres = data[filter]\n",
    "print(array_max_sucres[:,0]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SHsrGdy-5AZK"
   },
   "source": [
    "## EX03\n",
    "### Dataframes\n",
    "\n",
    "Refaire l'exo du TD 4 (fichier des series) en utilisant la librairie NumPy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "id": "jIatRWhm5Xzo",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# tv_shows2.csv\n",
    "from random import randint\n",
    "#filepath = \"./tv_shows2.csv\" \n",
    "def read_csv_numpy(filepath,separator) :\n",
    "    liste_series=[]\n",
    "    series = np.genfromtxt(filepath,\n",
    "                           delimiter=separator,\n",
    "                           names=True,\n",
    "                           dtype=None,\n",
    "                           encoding=None,\n",
    "                           invalid_raise=False,\n",
    "                           )\n",
    "    heads = series.dtype.names\n",
    "    for serie in series:\n",
    "        dict_serie ={}\n",
    "        dict_serie['Title'] = serie['Title']\n",
    "        plateforme = []\n",
    "        for i in range(6,10) :\n",
    "            if serie[i] == 1 :\n",
    "                plateforme.append(heads[i])\n",
    "                \n",
    "        dict_serie['plateforme'] = plateforme\n",
    "        nb_episodes = randint(6,30)\n",
    "        dict_serie['nb_episodes'] = nb_episodes\n",
    "        dict_serie['annÃ©e_sortie'] = serie['Year']\n",
    "        note = serie['IMDb'].split('/')\n",
    "        try :\n",
    "            note[0] = float(note[0])\n",
    "        except :\n",
    "            pass\n",
    "        dict_serie['note'] = note[0]\n",
    "        liste_series.append(dict_serie)\n",
    "    \n",
    "    return liste_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Title': 'Breaking Bad', 'plateforme': ['Netflix'], 'nb_episodes': 7, 'annÃ©e_sortie': 2008, 'note': 9.4} \n",
      "\n",
      "{'Title': 'Stranger Things', 'plateforme': ['Netflix'], 'nb_episodes': 22, 'annÃ©e_sortie': 2016, 'note': 8.7} \n",
      "\n",
      "{'Title': 'Attack on Titan', 'plateforme': ['Netflix', 'Hulu'], 'nb_episodes': 11, 'annÃ©e_sortie': 2013, 'note': 9.0} \n",
      "\n",
      "{'Title': 'Better Call Saul', 'plateforme': ['Netflix'], 'nb_episodes': 8, 'annÃ©e_sortie': 2015, 'note': 8.8} \n",
      "\n",
      "{'Title': 'Dark', 'plateforme': ['Netflix'], 'nb_episodes': 15, 'annÃ©e_sortie': 2017, 'note': 8.8} \n",
      "\n",
      "{'Title': 'Avatar: The Last Airbender', 'plateforme': ['Netflix', 'Prime_Video'], 'nb_episodes': 14, 'annÃ©e_sortie': 2005, 'note': 9.3} \n",
      "\n",
      "{'Title': 'Peaky Blinders', 'plateforme': ['Netflix'], 'nb_episodes': 21, 'annÃ©e_sortie': 2013, 'note': 8.8} \n",
      "\n",
      "{'Title': 'The Walking Dead', 'plateforme': ['Netflix'], 'nb_episodes': 12, 'annÃ©e_sortie': 2010, 'note': 8.2} \n",
      "\n",
      "{'Title': 'Black Mirror', 'plateforme': ['Netflix'], 'nb_episodes': 13, 'annÃ©e_sortie': 2011, 'note': 8.8} \n",
      "\n",
      "{'Title': \"The Queen's Gambit\", 'plateforme': ['Netflix'], 'nb_episodes': 29, 'annÃ©e_sortie': 2020, 'note': 8.6} \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\malas\\AppData\\Local\\Temp/ipykernel_10288/1128862373.py:6: ConversionWarning: Some errors were detected !\n",
      "    Line #893 (got 2 columns instead of 11)\n",
      "    Line #3370 (got 2 columns instead of 11)\n",
      "    Line #3425 (got 12 columns instead of 11)\n",
      "    Line #3447 (got 12 columns instead of 11)\n",
      "    Line #4301 (got 2 columns instead of 11)\n",
      "    Line #4463 (got 2 columns instead of 11)\n",
      "  series = np.genfromtxt(filepath,\n"
     ]
    }
   ],
   "source": [
    "liste_series = read_csv_numpy(\"./tv_shows.csv\",\"|\")\n",
    "for i in range(10) :\n",
    "    print(liste_series[i],'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "94-12vgPXG10"
   },
   "source": [
    "## Github 101\n",
    "\n",
    "```shell\n",
    "# Repartir sur une nouvelle branche\n",
    "git checkout main\n",
    "# Mettre Ã  jour notre branche locale\n",
    "git pull origin main\n",
    "# RecrÃ©er une branche pour le TD 05\n",
    "git checkout -b branch_name_td05\n",
    "# Dupliquer le fichier du td et rajouter en suffix son nom\n",
    "cd 'chemin/m1-miage/'\n",
    "cp 'src/to_do/td_05/td_05.ipynb' 'src/done/td_05/td_05_nom_prenom.ipynb'\n",
    "# Faire le travail necessaire sur votre fichier et commit et push\n",
    "git add 'src/done/td_05/td_05_nom_prenom.ipynb'\n",
    "git commit -m 'message descriptif du travail fait'\n",
    "git push --set-upstream origin nom_branche\n",
    "# Faire une pull request\n",
    "```\n",
    "\n",
    "[>>>PULL REQUEST<<<](https://github.com/lapointe05/m1-miage/pulls)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "597Hu82gSNCZ",
    "k2lJWv62kQZA",
    "94-12vgPXG10"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
