{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "597Hu82gSNCZ"
      },
      "source": [
        "<img src=\"https://upload.wikimedia.org/wikipedia/fr/0/0b/Polytech_Lyon_logo.png\" alt=\"drawing\" height=\"200\"/>\n",
        "\n",
        "# Traitement de donn√©es & Programmation en Python\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EA-XK862WiMt"
      },
      "source": [
        "# TD 05\n",
        "\n",
        "Traitement de donn√©es\n",
        "\n",
        "![Good luck!](https://media.tenor.com/YoFWnXe4V3kAAAAd/may-the-odds-be-ever-in-your-favor-may-the-odds-hunger-games.gif)\n",
        " \n",
        "Elements √† consulter:\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Doc                                   |             Link\n",
        "--------------------------------------|------------------------------------\n",
        "Github Helper      | [>link<](#scrollTo=Github_101)\n",
        "Python en 30 jours | [>link<](https://moncoachdata.com/courses/apprendre-python-en-30-jours/)\n",
        "Get started with pandas | [>link<](https://colab.research.google.com/notebooks/snippets/pandas.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y1g4EgT41MqJ"
      },
      "source": [
        "## Intro\n",
        "\n",
        "Le premier bloc devrait toujours contenir les installs/imports dont on aura besoin pour le reste"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yjiE8c51VoT0",
        "outputId": "2f4856bd-590b-4197-a9f0-e3a020d191eb"
      },
      "outputs": [],
      "source": [
        "# Installs\n",
        "print(\"Python is awesome üëç\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JhT-50uwz72F"
      },
      "outputs": [],
      "source": [
        "# Imports\n",
        "import os\n",
        "import json\n",
        "from random import randint\n",
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NsB9ADLg8i8P",
        "outputId": "162e09d0-12e6-4112-972d-91cea118215a"
      },
      "outputs": [],
      "source": [
        "x = np.array([[1, 2, 3], [4, 5, 6]], np.int32)\n",
        "\n",
        "x.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iKow2OZ5LCXr"
      },
      "source": [
        "### Correction TD precedent\n",
        "\n",
        "Partir d'un fichier csv et alimenter la binge watch list :\n",
        "  > serie, plateform, nb_episodes, ann√©e_sortie, note\n",
        "\n",
        "Puis print :\n",
        "\n",
        "\t Nom de la s√©rie : Brooklyn Nine-Nine\n",
        "\t Ann√©e de sortie : 2013\n",
        "\n",
        "\t Nom de la s√©rie : The office\n",
        "\t Ann√©e de sortie : 2005\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9lcQQFp3w0HE"
      },
      "outputs": [],
      "source": [
        "def csv_to_dict(file_path, separator=\";\", row_limit=None):\n",
        "    \"\"\"\n",
        "    Transforms a csv file, into a list of dictionaries\n",
        "\n",
        "    Arguments:\n",
        "        file_path  {str} : eg. /documents/file.txt\n",
        "        separator  {str} : separator of fields, default (;)\n",
        "        row_limit  {int} : limit the rows to be read, default None\n",
        "\n",
        "    Returns list[dict]\n",
        "    \"\"\"\n",
        "\n",
        "    with open(file_path, \"r\") as f:\n",
        "        serie = {}\n",
        "        serie_list = []\n",
        "        for i, row in enumerate(f, 1):\n",
        "            if i == 1:\n",
        "                header = row.lower().strip().replace(' ','_').split(separator)\n",
        "                # print(\"\\nHeaders:\", header,\"\\n\")\n",
        "            else:\n",
        "                data = row.lower().strip().split(separator)\n",
        "                # print(\"Data:\",data)\n",
        "                if len(header) == len(data):\n",
        "                    for j, element in enumerate(header):\n",
        "                        serie[header[j]] = data[j]\n",
        "            # print(serie)\n",
        "                serie_list.append(serie)\n",
        "                serie = {}\n",
        "            if i == row_limit:\n",
        "                break\n",
        "    return serie_list\n",
        "\n",
        "\n",
        "\n",
        "file_path = \"./netflix_titles.csv\"\n",
        "# file_path = \"./tv_shows_pipe.csv\"\n",
        "limit = None\n",
        "binge_watch_list = csv_to_dict(file_path,separator=\"|\",row_limit=limit)\n",
        "# for serie in binge_watch_list:\n",
        "#   print(serie.get('title'))\n",
        "# # Option 1 read some rows to see what we have\n",
        "\n",
        "df = pd.DataFrame(binge_watch_list)\n",
        "df[\"title\"] = df[\"title\"].str.title()\n",
        "df.head(5)\n",
        "\n",
        "column_name = 'release_year'\n",
        "filter = df['release_year'] == '2005'\n",
        "# df.query(f\"`{column_name}` == '2003'\")\n",
        "df[filter]\n",
        "# # serie, plateform, nb_episodes, ann√©e_sortie, note\n",
        "# df2 = df.melt(id_vars=['title','year','imdb','rotten_tomatoes'],\n",
        "#               var_name='plateform', \n",
        "#               value_vars=['netflix','hulu','prime_video','disney+'])\n",
        "# df2.drop(['value'], axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k2lJWv62kQZA"
      },
      "source": [
        "##EX01\n",
        "### Numpy intro\n",
        "\n",
        "* Cr√©er un vecteur depuis la liste ['Lyon', 'Paris', 'Montpellier']\n",
        "    * Assigner le r√©sultat √† la variable `villes`\n",
        "* Cr√©er une matrice depuis la liste de listes suivante: `[['Lyon', '69'], ['Paris', '75'], ['Montpellier','34']]`\n",
        "    * Assigner le r√©sultat √† la variable `villes_departement`\n",
        "* Assigner la taille du vecteur `villes` √† la variable `v_shape`\n",
        "* Assigner la taille du tableau `villes_departement` √† la variable `vd_shape` \n",
        "* Afficher les r√©sultats"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n_jOsgGllUhC"
      },
      "outputs": [],
      "source": [
        "# Code here\n",
        "\n",
        "# vecteur depuis la liste ['Lyon', 'Paris', 'Montpellier']\n",
        "\n",
        "villes = np.array(['Lyon', 'Paris', 'Montpellier'])\n",
        "print(villes)\n",
        "\n",
        "# Matrice depuis la liste [['Lyon','69'], ['Paris', '75'], ['Montpellier', '34']]\n",
        "\n",
        "villes_departement = np.array(\n",
        "    [['Lyon', 'Paris', 'Montpellier'], ['69', '75', '34']])\n",
        "print(villes_departement)\n",
        "\n",
        "v_shape = villes.shape\n",
        "print(v_shape)\n",
        "\n",
        "vd_shape = villes_departement.shape\n",
        "print(vd_shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q8WBS9oVKcWs"
      },
      "source": [
        "##EX02\n",
        "### Numpy intro\n",
        "\n",
        "#### Part 1\n",
        "\n",
        "* Telecharger le dataset [cereal.csv](https://www.kaggle.com/datasets/crawford/80-cereals?select=cereal.csv) avec les colonnes suivantes :\n",
        "\n",
        "```\n",
        "['name', 'mfr', 'type', 'calories', 'protein', 'fat', 'sodium', 'fiber',\n",
        "'carbo', 'sugars', 'potass', 'vitamins', 'shelf', 'weight', 'cups',\n",
        "'rating']\n",
        "```\n",
        "\n",
        "* Afficher les deux premieres colonnes et toute les lignes\n",
        "* Afficher la derni√®re colonne\n",
        "* Afficher les 5 premieres lignes de la 4√®me colonne\n",
        "* Assigner a une variable `corn_flakes_cals` le nombre de calories par 100 gr de c√©r√©ales de la marque Corn Flakes \n",
        "* Assigner le nom de la 3eme marque sur le dataset a une variabe `third_brand`\n",
        "* Mettre dans une liste toutes les marques de c√©reales en utilisant `.tolist()` & afficher cette derni√®re\n",
        "* Mettre les 10 premiere marques dans le fichiers dans une liste `first_ten_brands` & afficher cette derni√®re\n",
        "> bonus \n",
        "* Convertir la colonne ratings en d√©cimale"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XTDsqYIgpitx",
        "outputId": "d2cd6d75-cf4d-4421-c34f-097def1f3b94"
      },
      "outputs": [],
      "source": [
        "# Code here\n",
        "file_path = \"./cereal.csv\"\n",
        "data = np.genfromtxt(\n",
        "                file_path, \n",
        "                delimiter= ',', \n",
        "                dtype = \"str\", \n",
        "                autostrip = True,\n",
        "                skip_header= True\n",
        "                     )\n",
        "print(data.shape) ## retourne (lignes, colonnes)\n",
        "data\n",
        "\n",
        "print(\"###############################################################################\")\n",
        "print('les 2 premi√®res colonnes et toutes les lignes :')\n",
        "print(data[:, [0,1]]) \n",
        "\n",
        "print(\"###############################################################################\")\n",
        "print('la derniere colonne :')\n",
        "print(data [:, -1])\n",
        "\n",
        "print(\"###############################################################################\")\n",
        "print('Les 5 premi√®res lignes et la 4e colonnes')\n",
        "print(data [0:5, 3])\n",
        "\n",
        "print(\"###############################################################################\")\n",
        "print(\"Assignation a une variable corn_flake_cals le nombre de calories par 100 gr\\nde cereales de la marque Corn Flakes\")\n",
        "corn_flakes_cals = int (data[(data[:,0] == 'Corn Flakes'), 3])/100\n",
        "print(corn_flakes_cals)\n",
        "\n",
        "print(\"###############################################################################\")\n",
        "print(\"la 3e marque du dataset assign√©e √† une variable third_brand : \")\n",
        "third_brand = data[2,0]\n",
        "print(third_brand)\n",
        "\n",
        "print(\"###############################################################################\")\n",
        "print(\"Toutes les marques de cer√©ales dans une liste\")\n",
        "cereal = data.tolist()\n",
        "print(cereal)\n",
        "\n",
        "print(\"###############################################################################\")\n",
        "print(\" Les 10 premi√®res marques dans le fichier dans une liste first_ten_brands\")\n",
        "first_ten_brands = data[:10, ]\n",
        "print(first_ten_brands)\n",
        "\n",
        "# Bonus\n",
        "print(\"###############################################################################\")\n",
        "ratings_float = data [:,-1]\n",
        "print(\"convertir la colonne rating en d√©cimal :\",ratings_float.astype('float'))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8BaW1VvWXCS7"
      },
      "source": [
        "#### Part 2\n",
        "\n",
        "* **Extraire** la premiere colonne du dataset et **la comparer** √† la valeur `'Special K'` Assigner le resultat √† une variable `special_k`\n",
        "* Executer la commande `print(data[special_k])`\n",
        "> bonus\n",
        "* Faire la meme chose mais le filtre verifie que le manufacturer est Quaker Oats (lire la doc du dataset üòâ)\n",
        "> bonus ¬≤\n",
        "* Print le nom des marques dont le fabricant est `Quaker Oats` et qui contiennent **moins** de `10 grammes` de sucre par portion\n",
        "* Ajouter une marque de c√©r√©ales \"healthy\" avec 0 grammes de sucre au dataset "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GuXFyhUepnMc",
        "outputId": "6ec9c05d-a76c-4d8f-8c48-6285d32b6953"
      },
      "outputs": [],
      "source": [
        "# Code here\n",
        "\n",
        "# bonus\n",
        "special_k = data[:, 0] == 'Special K'\n",
        "print(data[special_k])\n",
        "print(\"###############################################################################\")\n",
        "\n",
        "\n",
        "# Faire la m√™me chose , mais le filtre v√©rifie que le manufacturer est Quaker Oats\n",
        "Quaker_Oats = data[:, 1] == \"Q\"\n",
        "print(data[Quaker_Oats])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NdsY64gl_0dw"
      },
      "source": [
        "#### Part 3\n",
        "\n",
        "Sur le m√™me dataset, √† l'aide d'une boucle `for`:\n",
        "\n",
        "\n",
        "*   Cr√©er un dictionnaire avec la moyenne de sucre par Fabricant de c√©rales\n",
        "*   Trouver la marque de c√©reales qui contient le plus de sucre par portion\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EjbTgYNbCaIj",
        "outputId": "5ab1f623-f8df-45f2-e82b-7031da73f3f5"
      },
      "outputs": [],
      "source": [
        "# A l'aide d'une boucle for, creer un dictionnaire avec la moyenne de sucre par fabricant de c√©reales\n",
        "\n",
        "fabricants = {\n",
        "\n",
        "    \"American Home Food Products\":\"A\" ,\n",
        "    \"General Mills\":\"G\",\n",
        "    \"Kelloggs\":\"K\",\n",
        "    \"Nabisco\":\"N\",\n",
        "    \"Post\":\"P\",\n",
        "    \"Quaker Oats\":\"Q\",\n",
        "    \"Ralston Purina\":\"R\"\n",
        "}\n",
        "moyenne_sucre_fabricant ={}\n",
        "\n",
        "for fabricant in fabricants:\n",
        "    par_fabricant = data[:,1] == fabricants[fabricant]\n",
        "    set_fabricant = data[par_fabricant]\n",
        "    moyenne_sucre = np.mean(set_fabricant[:,9].astype('float'))\n",
        "    moyenne_sucre_fabricant[fabricant] = moyenne_sucre\n",
        "print(\"Les moyennes de sucres pour chaque fabricant : \", moyenne_sucre_fabricant)\n",
        "\n",
        "print('##############################################################################')\n",
        "\n",
        "print(f\"La marque de c√©reales qui contient le plus de sucre par portions '{max(moyenne_sucre_fabricant, key=moyenne_sucre_fabricant.get)}' portion de sucre elev√©e\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w1wjqra3_yZo",
        "outputId": "ea12a660-30c6-45d0-e066-c7f4848eb455"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SHsrGdy-5AZK"
      },
      "source": [
        "## EX03\n",
        "### Dataframes\n",
        "\n",
        "Refaire l'exo du TD 4 (fichier des series) en utilisant la librairie NumPy.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jIatRWhm5Xzo"
      },
      "outputs": [],
      "source": [
        "# Code here\n",
        "\n",
        "netflix_file_path = \"./netflix_titles.csv\"\n",
        "\n",
        "limit = None\n",
        "data = np.genfromtxt(\n",
        "    fname=netflix_file_path,\n",
        "    delimiter='|',\n",
        "    dtype='U100',\n",
        "    autostrip=True,\n",
        "    skip_header=1,\n",
        "    max_rows=limit,\n",
        "    invalid_raise= False    # Pour r√©soudre le probl√®me de lignes ayant un mauvais nombre de colonnes d√©tect√©es. \n",
        "                            # Permet de ne pas garder les lignes probl√©matiques.\n",
        ")\n",
        "filter_series = data[:, 1] == \"TV Show\"\n",
        "data = data[filter_series]\n",
        "interested_data = data[:, (2, 7, 9)]\n",
        "\n",
        "netflix_series = []\n",
        "for data in interested_data:\n",
        "    netflix_series.append({\n",
        "        \"Nom s√©rie\" : data[0],\n",
        "        \"Date sortie\" : data[1],\n",
        "        \"Nombre saisons\" : data[2],\n",
        "        \"Streaming\" : \"Netflix\",\n",
        "        \"Note\" : f\"{randint(0,10)}/10\",\n",
        "    })\n",
        "\n",
        "print(netflix_series)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "94-12vgPXG10"
      },
      "source": [
        "## Github 101\n",
        "\n",
        "```shell\n",
        "# Repartir sur une nouvelle branche\n",
        "git checkout main\n",
        "# Mettre √† jour notre branche locale\n",
        "git pull origin main\n",
        "# Recr√©er une branche pour le TD 05\n",
        "git checkout -b branch_name_td05\n",
        "# Dupliquer le fichier du td et rajouter en suffix son nom\n",
        "cd 'chemin/m1-miage/'\n",
        "cp 'src/to_do/td_05/td_05.ipynb' 'src/done/td_05/td_05_nom_prenom.ipynb'\n",
        "# Faire le travail necessaire sur votre fichier et commit et push\n",
        "git add 'src/done/td_05/td_05_nom_prenom.ipynb'\n",
        "git commit -m 'message descriptif du travail fait'\n",
        "git push --set-upstream origin nom_branche\n",
        "# Faire une pull request\n",
        "```\n",
        "\n",
        "[>>>PULL REQUEST<<<](https://github.com/lapointe05/m1-miage/pulls)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "597Hu82gSNCZ",
        "k2lJWv62kQZA",
        "94-12vgPXG10"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "1889d7668b2a47aacb7847985e9bd9ce556bbd9a68ed9bf372d36594c96221b2"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
